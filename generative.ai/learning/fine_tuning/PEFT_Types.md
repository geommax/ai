# PEFT (Parameter-Efficient Fine-Tuning) á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€»á€¬á€¸

## PEFT á€†á€­á€¯á€á€¬á€˜á€¬á€œá€²?

PEFT á€†á€­á€¯á€á€¬ **Parameter-Efficient Fine-Tuning** á€›á€²á€· á€¡á€á€­á€¯á€€á€±á€¬á€€á€ºá€–á€¼á€…á€ºá€•á€¼á€®á€¸áŠ LLM (Large Language Model) á€á€…á€ºá€á€¯á€œá€¯á€¶á€¸á€€á€­á€¯ fine-tune á€œá€¯á€•á€ºá€™á€šá€·á€ºá€¡á€…á€¬á€¸ **parameter á€¡á€”á€Šá€ºá€¸á€„á€šá€ºá€€á€­á€¯á€á€¬** á€•á€¼á€„á€ºá€†á€„á€ºá€•á€¼á€®á€¸ fine-tune á€œá€¯á€•á€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹

### Full Fine-Tuning vs PEFT

| | Full Fine-Tuning | PEFT |
|---|---|---|
| **á€•á€¼á€„á€ºá€†á€„á€ºá€á€²á€· Parameters** | Model parameter á€¡á€¬á€¸á€œá€¯á€¶á€¸ | Parameter á€¡á€”á€Šá€ºá€¸á€„á€šá€º (0.1% - 10%) |
| **GPU Memory** | á€¡á€›á€™á€ºá€¸á€™á€»á€¬á€¸á€™á€»á€¬á€¸á€œá€­á€¯á€¡á€•á€º | á€”á€Šá€ºá€¸á€”á€Šá€ºá€¸á€•á€²á€œá€­á€¯á€¡á€•á€º |
| **Training Time** | á€€á€¼á€¬á€á€šá€º | á€™á€¼á€”á€ºá€á€šá€º |
| **Catastrophic Forgetting** | á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá€á€¼á€±á€™á€»á€¬á€¸ | á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá€á€¼á€±á€”á€Šá€ºá€¸ |
| **Storage** | Model á€á€…á€ºá€á€¯á€œá€¯á€¶á€¸ save á€›á€á€šá€º | Adapter weights á€œá€±á€¸á€•á€² save á€›á€á€šá€º |

---

## PEFT á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸á€™á€»á€¬á€¸

PEFT methods á€á€½á€±á€€á€­á€¯ á€¡á€“á€­á€€ **áƒ á€™á€»á€­á€¯á€¸** á€á€½á€²á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€ºá‹

### 1. Additive Methods (á€‘á€•á€ºá€‘á€Šá€·á€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€™á€»á€¬á€¸)

Original model á€€á€­á€¯ á€™á€•á€¼á€„á€ºá€˜á€² **parameter á€¡á€á€…á€ºá€á€½á€± á€‘á€•á€ºá€‘á€Šá€·á€º** á€•á€¼á€®á€¸ train á€œá€¯á€•á€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹

### 2. Selective Methods (á€›á€½á€±á€¸á€á€»á€šá€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€™á€»á€¬á€¸)

Model á€›á€²á€· **parameter á€¡á€á€»á€­á€¯á€·á€€á€­á€¯á€á€¬ á€›á€½á€±á€¸á€á€»á€šá€º** á€•á€¼á€®á€¸ train á€œá€¯á€•á€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹

### 3. Reparameterization Methods (á€•á€¼á€”á€ºá€œá€Šá€ºá€–á€½á€²á€·á€…á€Šá€ºá€¸á€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€™á€»á€¬á€¸)

Model á€›á€²á€· weight matrices á€á€½á€±á€€á€­á€¯ **low-rank representation** á€”á€²á€· á€•á€¼á€”á€ºá€œá€Šá€ºá€–á€½á€²á€·á€…á€Šá€ºá€¸á€•á€¼á€®á€¸ train á€œá€¯á€•á€ºá€á€²á€· á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€–á€¼á€…á€ºá€•á€«á€á€šá€ºá‹

---

## PEFT á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€™á€»á€¬á€¸ á€¡á€á€±á€¸á€…á€­á€á€º

---

### ğŸ”· 1. LoRA (Low-Rank Adaptation)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Reparameterization Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

LoRA á€Ÿá€¬ model á€›á€²á€· weight matrix `W` á€€á€­á€¯ directly á€•á€¼á€„á€ºá€™á€šá€·á€ºá€¡á€…á€¬á€¸áŠ **low-rank decomposition** á€€á€­á€¯á€á€¯á€¶á€¸á€•á€¼á€®á€¸ update matrix `Î”W` á€€á€­á€¯ `A Ã— B` á€¡á€–á€¼á€…á€º á€á€½á€²á€‘á€¯á€á€ºá€•á€«á€á€šá€ºá‹

```
W' = W + Î”W = W + (A Ã— B)
```

- `W` = Original weight matrix (frozen, train á€™á€œá€¯á€•á€º)
- `A` = Down-projection matrix (d Ã— r)
- `B` = Up-projection matrix (r Ã— d)
- `r` = Rank (LoRA rank, e.g., 8, 16, 32, 64)

#### á€¥á€•á€™á€¬

Original weight matrix `W` á€›á€²á€· size á€€ `4096 Ã— 4096` á€†á€­á€¯á€›á€„á€º:
- Full fine-tune: `4096 Ã— 4096 = 16,777,216` parameters
- LoRA (r=8): `(4096 Ã— 8) + (8 Ã— 4096) = 65,536` parameters â†’ **~0.4% á€á€¬**

#### Key Hyperparameters

| Parameter | á€›á€¾á€„á€ºá€¸á€œá€„á€ºá€¸á€á€»á€€á€º | Common Values |
|---|---|---|
| `lora_r` | Rank - Low-rank matrix á€›á€²á€· dimension | 8, 16, 32, 64 |
| `lora_alpha` | Scaling factor (alpha/r = scaling) | 16, 32 |
| `lora_dropout` | Dropout rate for regularization | 0.05, 0.1 |
| `lora_target_modules` | LoRA apply á€œá€¯á€•á€ºá€™á€šá€·á€º layers | `q_proj`, `v_proj`, `k_proj`, `o_proj` |

#### Axolotl Config Example

```yaml
adapter: lora
lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj
```

---

### ğŸ”· 2. QLoRA (Quantized LoRA)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Reparameterization Method + Quantization

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

QLoRA á€Ÿá€¬ LoRA á€›á€²á€· extension á€–á€¼á€…á€ºá€•á€¼á€®á€¸áŠ base model á€€á€­á€¯ **4-bit quantization** á€œá€¯á€•á€ºá€•á€¼á€®á€¸á€™á€¾ LoRA adapters á€‘á€Šá€·á€ºá€•á€«á€á€šá€ºá‹

```
Frozen Base Model (4-bit quantized) + LoRA Adapters (trainable, fp16/bf16)
```

#### QLoRA á€›á€²á€· Key Innovations

1. **4-bit NormalFloat (NF4)** - Normal distribution á€¡á€á€½á€€á€º optimal quantization data type
2. **Double Quantization** - Quantization constants á€€á€­á€¯á€•á€« á€‘á€•á€º quantize á€œá€¯á€•á€ºá€•á€¼á€®á€¸ memory á€•á€­á€¯á€á€€á€ºá€á€¬á€¡á€±á€¬á€„á€ºá€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸
3. **Paged Optimizers** - GPU memory overflow á€€á€­á€¯ CPU RAM á€€á€­á€¯ page á€œá€¯á€•á€ºá€•á€¼á€®á€¸ á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€¼á€„á€ºá€¸

#### Memory Comparison

| Method | 7B Model Memory |
|---|---|
| Full Fine-Tuning (fp16) | ~28 GB |
| LoRA (fp16) | ~14 GB |
| QLoRA (4-bit) | ~6 GB |

#### Axolotl Config Example

```yaml
adapter: qlora
load_in_4bit: true
lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
```

---

### ğŸ”· 3. DoRA (Weight-Decomposed Low-Rank Adaptation)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Reparameterization Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

DoRA á€Ÿá€¬ LoRA á€€á€­á€¯ improve á€œá€¯á€•á€ºá€‘á€¬á€¸á€á€¬á€–á€¼á€…á€ºá€•á€¼á€®á€¸áŠ weight matrix á€€á€­á€¯ **magnitude** á€”á€²á€· **direction** á€†á€­á€¯á€•á€¼á€®á€¸ á‚ á€•á€­á€¯á€„á€ºá€¸ á€á€½á€²á€•á€«á€á€šá€ºá‹

```
W' = m Ã— (V + Î”V) / ||V + Î”V||
```

- `m` = Magnitude vector (trainable)
- `V` = Direction matrix (LoRA á€”á€²á€· update)
- `Î”V` = LoRA update for direction

#### LoRA vs DoRA

- **LoRA**: Magnitude á€”á€²á€· direction á€€á€­á€¯ á€á€…á€ºá€•á€¼á€­á€¯á€„á€ºá€”á€€á€º update á€œá€¯á€•á€ºá€á€šá€º
- **DoRA**: Magnitude á€”á€²á€· direction á€€á€­á€¯ **á€á€®á€¸á€á€¼á€¬á€¸** update á€œá€¯á€•á€ºá€á€šá€º â†’ full fine-tuning á€›á€²á€· learning pattern á€”á€²á€· á€•á€­á€¯á€”á€®á€¸á€…á€•á€º

#### Axolotl Config Example

```yaml
adapter: lora
lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
peft_use_dora: true
```

---

### ğŸ”· 4. Prompt Tuning

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Additive Method (Soft Prompts)

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Model á€›á€²á€· input embedding layer á€›á€²á€· **á€›á€¾á€±á€·á€†á€¯á€¶á€¸á€™á€¾á€¬** trainable virtual tokens (soft prompts) á€á€½á€± á€‘á€Šá€·á€ºá€•á€¼á€®á€¸ train á€œá€¯á€•á€ºá€•á€«á€á€šá€ºá‹

```
Input = [Soft Prompt Tokens] + [Actual Input Tokens]
         (trainable)           (frozen embeddings)
```

- Soft prompt á€›á€²á€· embedding vectors á€á€½á€±á€€á€­á€¯á€á€¬ train á€œá€¯á€•á€ºá€•á€«á€á€šá€º
- Model weights á€¡á€¬á€¸á€œá€¯á€¶á€¸ frozen á€–á€¼á€…á€ºá€•á€«á€á€šá€º
- Task-specific soft prompts á€á€½á€±á€€á€­á€¯ swap á€œá€¯á€•á€ºá€•á€¼á€®á€¸ multi-task serving á€œá€¯á€•á€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º

#### Trainable Parameters

Soft prompt length = 20 tokens, embedding dim = 4096 á€†á€­á€¯á€›á€„á€º:
- `20 Ã— 4096 = 81,920` parameters á€á€¬ train á€›á€•á€«á€á€šá€º

---

### ğŸ”· 5. Prefix Tuning

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Additive Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Prompt Tuning á€”á€²á€· á€†á€„á€ºá€á€°á€•á€±á€™á€šá€·á€ºáŠ **transformer á€›á€²á€· layer á€á€­á€¯á€„á€ºá€¸á€™á€¾á€¬** trainable prefix vectors á€á€½á€± á€‘á€Šá€·á€ºá€•á€«á€á€šá€ºá‹

```
Layer_i_output = Attention(prefix_key_i, prefix_value_i, input)
```

- Input embedding layer á€™á€¾á€¬á€•á€² á€™á€Ÿá€¯á€á€ºá€˜á€² **every layer** á€›á€²á€· key-value pairs á€™á€¾á€¬ prefix á€‘á€Šá€·á€ºá€•á€«á€á€šá€º
- Prompt Tuning á€‘á€€á€º expressiveness á€•á€­á€¯á€€á€±á€¬á€„á€ºá€¸á€•á€«á€á€šá€º
- Parameters á€•á€­á€¯á€™á€»á€¬á€¸á€•á€«á€á€šá€º (layer count Ã— prefix_length Ã— hidden_dim Ã— 2)

---

### ğŸ”· 6. P-Tuning v2

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Additive Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Prefix Tuning á€›á€²á€· improved version á€–á€¼á€…á€ºá€•á€¼á€®á€¸:

- Deep prompt tuning: **Layer á€á€­á€¯á€„á€ºá€¸á€™á€¾á€¬** trainable continuous prompts á€‘á€Šá€·á€ºá€•á€«á€á€šá€º
- Reparameterization á€€á€­á€¯ optional á€–á€¼á€…á€ºá€…á€±á€•á€«á€á€šá€º (MLP encoder á€™á€œá€­á€¯á€¡á€•á€º)
- NLU tasks á€á€½á€±á€™á€¾á€¬ full fine-tuning á€”á€²á€· comparable performance á€›á€•á€«á€á€šá€º

---

### ğŸ”· 7. IAÂ³ (Infused Adapter by Inhibiting and Amplifying Inner Activations)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Additive Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Model á€›á€²á€· activations (key, value, feedforward) á€á€½á€±á€€á€­á€¯ **learned vectors** á€”á€²á€· element-wise multiply (rescale) á€œá€¯á€•á€ºá€•á€«á€á€šá€ºá‹

```
k' = l_k âŠ™ k    (key activations á€€á€­á€¯ rescale)
v' = l_v âŠ™ v    (value activations á€€á€­á€¯ rescale)
ff' = l_ff âŠ™ ff  (feedforward activations á€€á€­á€¯ rescale)
```

- `l_k`, `l_v`, `l_ff` = Learned rescaling vectors (trainable)
- LoRA á€‘á€€á€º trainable parameters **á€¡á€™á€»á€¬á€¸á€€á€¼á€®á€¸ á€”á€Šá€ºá€¸á€•á€«á€á€šá€º**
- Few-shot learning á€™á€¾á€¬ á€€á€±á€¬á€„á€ºá€¸á€•á€«á€á€šá€º

---

### ğŸ”· 8. Adapter Layers (Bottleneck Adapters)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Additive Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Transformer layer á€á€­á€¯á€„á€ºá€¸á€›á€²á€· **attention á€”á€²á€· feedforward sublayer á€€á€¼á€¬á€¸á€™á€¾á€¬** small bottleneck modules (adapters) á€‘á€Šá€·á€ºá€•á€«á€á€šá€ºá‹

```
Adapter(x) = x + f(x Ã— W_down) Ã— W_up

W_down: d â†’ r  (down-project)
f: activation function (ReLU/GELU)
W_up: r â†’ d    (up-project)
```

- Original model weights freeze á€‘á€¬á€¸á€•á€¼á€®á€¸ adapter layers á€€á€­á€¯á€á€¬ train á€œá€¯á€•á€ºá€•á€«á€á€šá€º
- Bottleneck dimension `r` á€€á€­á€¯ á€á€»á€­á€”á€ºá€Šá€¾á€­á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º
- Residual connection á€•á€«á€á€„á€ºá€•á€«á€á€šá€º

---

### ğŸ”· 9. LoftQ (LoRA-Fine-Tuning-aware Quantization)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Reparameterization + Quantization

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

QLoRA á€€á€­á€¯ improve á€œá€¯á€•á€ºá€‘á€¬á€¸á€á€²á€· method á€–á€¼á€…á€ºá€•á€¼á€®á€¸:

- Quantization error á€€á€­á€¯ LoRA initialization á€™á€¾á€¬ compensate á€œá€¯á€•á€ºá€•á€«á€á€šá€º
- Quantized weight + LoRA á€›á€²á€· sum á€Ÿá€¬ original weight á€”á€²á€· **á€•á€­á€¯á€”á€®á€¸á€€á€•á€º** á€¡á€±á€¬á€„á€º initialize á€œá€¯á€•á€ºá€•á€«á€á€šá€º
- QLoRA á€‘á€€á€º convergence á€•á€­á€¯á€€á€±á€¬á€„á€ºá€¸á€•á€«á€á€šá€º

```
min ||W - (Q + AB)||  (Alternating optimization)
```

---

### ğŸ”· 10. NEFTune (Noisy Embeddings for Fine-Tuning)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Training Technique (PEFT á€”á€²á€· á€á€½á€²á€á€¯á€¶á€¸á€œá€­á€¯á€·á€›)

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

Training input embeddings á€á€½á€±á€™á€¾á€¬ **uniform random noise** á€‘á€Šá€·á€ºá€•á€¼á€®á€¸ train á€œá€¯á€•á€ºá€•á€«á€á€šá€ºá‹

```
embedding_noisy = embedding + Î± Ã— uniform_noise / âˆš(L Ã— d)
```

- `Î±` = Noise scale (neftune_noise_alpha, e.g., 5, 10, 15)
- `L` = Sequence length
- `d` = Embedding dimension
- Inference á€™á€¾á€¬ noise á€™á€‘á€Šá€·á€ºá€•á€«

#### Axolotl Config Example

```yaml
neftune_noise_alpha: 5
```

---

### ğŸ”· 11. ReLoRA (Stacked LoRA)

**á€¡á€™á€»á€­á€¯á€¸á€¡á€…á€¬á€¸:** Reparameterization Method

#### á€¡á€œá€¯á€•á€ºá€œá€¯á€•á€ºá€•á€¯á€¶

LoRA adapters á€€á€­á€¯ **periodically merge** á€œá€¯á€•á€ºá€•á€¼á€®á€¸ **reset** á€€á€¬ á€‘á€•á€ºá€á€«á€‘á€•á€ºá€á€« train á€œá€¯á€•á€ºá€•á€«á€á€šá€ºá‹

```
Loop:
  1. Train LoRA for N steps
  2. Merge: W = W + A Ã— B
  3. Reset A, B to new initialization
  4. Repeat
```

- High-rank updates á€€á€­á€¯ low-rank LoRA á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€¼á€®á€¸ approximate á€œá€¯á€•á€ºá€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º
- Pre-training stage á€™á€¾á€¬ LoRA á€€á€­á€¯ á€‘á€­á€›á€±á€¬á€€á€ºá€…á€½á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€”á€­á€¯á€„á€ºá€•á€«á€á€šá€º

#### Axolotl Config Example

```yaml
adapter: lora
relora_steps: 200
relora_warmup_steps: 50
```

---

## Axolotl á€™á€¾á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€œá€­á€¯á€·á€›á€á€²á€· PEFT Methods á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º

| PEFT Method | Axolotl Support | Config Key | á€™á€¾á€á€ºá€á€»á€€á€º |
|---|---|---|---|
| **LoRA** | âœ… Full Support | `adapter: lora` | á€¡á€á€¯á€¶á€¸á€¡á€™á€»á€¬á€¸á€†á€¯á€¶á€¸ PEFT method |
| **QLoRA** | âœ… Full Support | `adapter: qlora` | GPU memory á€”á€Šá€ºá€¸á€á€²á€·á€á€°á€¡á€á€½á€€á€º á€¡á€€á€±á€¬á€„á€ºá€¸á€†á€¯á€¶á€¸ |
| **DoRA** | âœ… Support | `peft_use_dora: true` | LoRA á€‘á€€á€º performance á€•á€­á€¯á€€á€±á€¬á€„á€ºá€¸ |
| **NEFTune** | âœ… Support | `neftune_noise_alpha: 5` | LoRA/QLoRA á€”á€²á€· á€á€½á€²á€á€¯á€¶á€¸á€œá€­á€¯á€·á€› |
| **ReLoRA** | âœ… Support | `relora_steps: 200` | Stacked LoRA training |
| **LoftQ** | âœ… Support | `peft_use_loftq: true` | Better quantization-aware init |
| **Prompt Tuning** | âš ï¸ Limited | PEFT library á€€á€”á€± | Axolotl direct config á€”á€Šá€ºá€¸ |
| **Prefix Tuning** | âš ï¸ Limited | PEFT library á€€á€”á€± | Axolotl direct config á€”á€Šá€ºá€¸ |
| **IAÂ³** | âš ï¸ Limited | PEFT library á€€á€”á€± | Axolotl direct config á€”á€Šá€ºá€¸ |
| **Adapter Layers** | âŒ Not Direct | - | Axolotl á€™á€¾á€¬ native support á€™á€›á€¾á€­ |

---

## Axolotl PEFT Config Template (Recommended)

### LoRA (Standard GPU - 24GB+)

```yaml
base_model: meta-llama/Llama-3.1-8B-Instruct
adapter: lora
lora_r: 32
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj

sequence_len: 4096
gradient_accumulation_steps: 4
micro_batch_size: 2
num_epochs: 3
learning_rate: 2e-4
optimizer: adamw_torch
lr_scheduler: cosine
bf16: auto
neftune_noise_alpha: 5
```

### QLoRA (Low VRAM GPU - 8GB+)

```yaml
base_model: meta-llama/Llama-3.1-8B-Instruct
adapter: qlora
load_in_4bit: true
lora_r: 64
lora_alpha: 32
lora_dropout: 0.05
lora_target_linear: true
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj

sequence_len: 2048
gradient_accumulation_steps: 4
micro_batch_size: 1
num_epochs: 3
learning_rate: 2e-4
optimizer: paged_adamw_8bit
lr_scheduler: cosine
bf16: auto
neftune_noise_alpha: 5
```

---

## PEFT Method á€›á€½á€±á€¸á€á€»á€šá€ºá€›á€¬á€™á€¾á€¬ á€œá€™á€ºá€¸á€Šá€½á€¾á€”á€º

```
GPU VRAM á€˜á€šá€ºá€œá€±á€¬á€€á€ºá€›á€¾á€­á€œá€²?
â”‚
â”œâ”€â”€ 8GB á€¡á€±á€¬á€€á€º â”€â”€â†’ QLoRA (4-bit) + low batch size
â”‚
â”œâ”€â”€ 8-16GB â”€â”€â†’ QLoRA (4-bit) recommended
â”‚
â”œâ”€â”€ 16-24GB â”€â”€â†’ LoRA (fp16/bf16) or QLoRA
â”‚
â”œâ”€â”€ 24-48GB â”€â”€â†’ LoRA + DoRA á€€á€­á€¯ á€…á€™á€ºá€¸á€€á€¼á€Šá€·á€º
â”‚
â””â”€â”€ 48GB+ â”€â”€â†’ LoRA / Full Fine-Tuning á€›á€½á€±á€¸á€á€»á€šá€ºá€”á€­á€¯á€„á€º
```

### LoRA vs QLoRA á€›á€½á€±á€¸á€á€»á€šá€ºá€á€¼á€„á€ºá€¸

- **QLoRA** á€€á€­á€¯ á€á€¯á€¶á€¸á€•á€« â†’ GPU memory **á€¡á€€á€”á€·á€ºá€¡á€á€á€º** á€›á€¾á€­á€›á€„á€º
- **LoRA** á€€á€­á€¯ á€á€¯á€¶á€¸á€•á€« â†’ GPU memory **á€œá€¯á€¶á€œá€±á€¬á€€á€º** á€•á€¼á€®á€¸ quality á€€á€­á€¯ á€¦á€¸á€…á€¬á€¸á€•á€±á€¸á€á€»á€„á€ºá€›á€„á€º
- **DoRA** á€€á€­á€¯ á€‘á€•á€ºá€‘á€Šá€·á€ºá€•á€« â†’ LoRA á€‘á€€á€º **performance á€•á€­á€¯á€œá€­á€¯á€á€»á€„á€º** á€›á€„á€º (memory á€¡á€”á€Šá€ºá€¸á€„á€šá€º á€•á€­á€¯á€€á€¯á€”á€º)
- **NEFTune** á€€á€­á€¯ á€¡á€™á€¼á€²á€á€½á€²á€á€¯á€¶á€¸á€•á€« â†’ **generalization á€€á€±á€¬á€„á€ºá€¸á€…á€±** á€á€šá€º
- **ReLoRA** á€€á€­á€¯ á€á€¯á€¶á€¸á€•á€« â†’ **pre-training** or **continued pre-training** á€œá€¯á€•á€ºá€á€»á€„á€ºá€›á€„á€º

---

## LoRA Target Modules - Model Architecture á€¡á€œá€­á€¯á€€á€º

| Model | Common Target Modules |
|---|---|
| **LLaMA / Llama 2/3** | `q_proj`, `v_proj`, `k_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj` |
| **Mistral** | `q_proj`, `v_proj`, `k_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj` |
| **GPT-NeoX** | `query_key_value`, `dense`, `dense_h_to_4h`, `dense_4h_to_h` |
| **Falcon** | `query_key_value`, `dense`, `dense_h_to_4h`, `dense_4h_to_h` |
| **Phi-2/3** | `q_proj`, `v_proj`, `k_proj`, `dense`, `fc1`, `fc2` |
| **Gemma** | `q_proj`, `v_proj`, `k_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj` |

> ğŸ’¡ **Tip:** `lora_target_linear: true` á€€á€­á€¯ á€á€¯á€¶á€¸á€›á€„á€º **linear layer á€¡á€¬á€¸á€œá€¯á€¶á€¸á€€á€­á€¯** auto-target á€œá€¯á€•á€ºá€•á€±á€¸á€•á€¼á€®á€¸ model-specific modules á€€á€­á€¯ manually specify á€™á€œá€­á€¯á€á€±á€¬á€·á€•á€«á‹
